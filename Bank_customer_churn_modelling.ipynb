{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00b3e5> Q1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print the data types of all the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Datatypes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RowNumber</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CustomerId</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surname</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CreditScore</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geography</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gender</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Age</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tenure</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balance</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NumOfProducts</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HasCrCard</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IsActiveMember</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EstimatedSalary</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Exited</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Columns Datatypes\n",
       "0         RowNumber     int64\n",
       "1        CustomerId     int64\n",
       "2           Surname    object\n",
       "3       CreditScore     int64\n",
       "4         Geography    object\n",
       "5            Gender    object\n",
       "6               Age     int64\n",
       "7            Tenure     int64\n",
       "8           Balance   float64\n",
       "9     NumOfProducts     int64\n",
       "10        HasCrCard     int64\n",
       "11   IsActiveMember     int64\n",
       "12  EstimatedSalary   float64\n",
       "13           Exited     int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT=data.dtypes.to_frame(name='Datatypes')\n",
    "DT.reset_index(level=None, drop=False, inplace=True)\n",
    "DT.rename(columns ={'index':'Columns'},inplace=True)\n",
    "DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for any incorrect values for the object datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column Surname ,has the following exceptions:\n",
      "9         H?\n",
      "329       L?\n",
      "437      Hs?\n",
      "941     Y?an\n",
      "970       L?\n",
      "        ... \n",
      "9633      K?\n",
      "9704      L?\n",
      "9792      Y?\n",
      "9857      K?\n",
      "9910      L?\n",
      "Name: Surname, Length: 92, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns[data.dtypes == 'object']:  \n",
    "    temp= pd.DataFrame(data[col].str.isdigit())\n",
    "    temp= pd.DataFrame(data[col].str.contains('[\\?*&^%$#@!]')== True)\n",
    "    res = (temp[col].values == True).sum()\n",
    "    ans=''\n",
    "    if res>0:\n",
    "        print(\"\\033[1m\" + \"The column\",col,\",has the following exceptions:\"  + \"\\033[0m\" )\n",
    "        print(data.loc[data[col].astype(str).str.contains('[\\?*&^%$#@!]') == True][col])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Smith       32\n",
       "Scott       29\n",
       "Martin      29\n",
       "Walker      28\n",
       "Brown       26\n",
       "Genovese    25\n",
       "Yeh         25\n",
       "Shih        25\n",
       "Maclean     24\n",
       "Wright      24\n",
       "White       23\n",
       "Wilson      23\n",
       "Fanucci     23\n",
       "Ma          23\n",
       "Chu         22\n",
       "Name: Surname, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Surname'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I am not going to use Surname column in the classification model as it doesn't contribue to large groupings (Inferred from the number of distincts in each unique value group for the column Surname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for any Missing Values (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber 0\n",
      "CustomerId 0\n",
      "Surname 0\n",
      "CreditScore 0\n",
      "Geography 0\n",
      "Gender 0\n",
      "Age 0\n",
      "Tenure 0\n",
      "Balance 0\n",
      "NumOfProducts 0\n",
      "HasCrCard 0\n",
      "IsActiveMember 0\n",
      "EstimatedSalary 0\n",
      "Exited 0\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(col,sum(data[col].isna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00b3e5> Q2.Drop the columns which are unique for all users like IDs (2.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing RowNumber , CustomerId and Surname by slicing the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00b3e5> Q3. Distinguish the feature and target set (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,3:13] #Features\n",
    "y=data.iloc[:,-1]   #Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert categorical variable into dummy/indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
       "0               1        101348.88                 1                  0   \n",
       "1               1        112542.58                 0                  0   \n",
       "2               0        113931.57                 1                  0   \n",
       "3               0         93826.63                 1                  0   \n",
       "4               1         79084.10                 0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                0              1            0  \n",
       "1                1              1            0  \n",
       "2                0              1            0  \n",
       "3                0              1            0  \n",
       "4                1              1            0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X,columns=['Geography','Gender'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00b3e5> Q4. Divide the data set into training and test sets ( 2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train, y_test= train_test_split(X,y,test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00b3e5> Q5. Normalize the train and test data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing the data before building a Neural network is important as the subsequent layers can get both positive and negative values , hence contributing to the learning more efficiently. In addition to this, scaling of the inputs on a similar level is important pre-processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "X_train_std=sc.fit_transform(X_train)\n",
    "X_test_std=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: Only fit_transform() is used on the train data for the scaling the train data. However, we only use transform() on the test data because the scaling paramaters learnt on the train data is now used to scale the test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00b3e5> Q6. Initialize & build the model. [ Make sure that you add 2 to 5 hidden dense layers in this model ] (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I am using TF Sequential classifier. \n",
    "##### RelU used in all hidden layer and inpur layer: The ReLU function is a non-linear  function that  does not activate all the neurons at the same time. The purpose of the activation function is to introduce non-linearity into the network.\n",
    "##### For final output layer of the classification model, I am using the Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Dense(20,activation='relu',input_dim=X_train_std.shape[1]))\n",
    "classifier.add(Dense(12, activation='relu'))\n",
    "classifier.add(Dense(10, activation='relu'))\n",
    "classifier.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Epochs: Cycle of dataset moving forward and backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After trying few combination of Epochs, Batch Size and Learning Rate, I have concluded the below parameters for this model. For more complex model, optimization techniques such as Keras Tuner can be implemented.\n",
    "##### SInce the Target variable is a binary output, hence I am using \"binary_crossentropy\" loss function. For multi class classification, categorical_crossentropy is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.89 - 0s 13us/step - loss: 0.2988 - accuracy: 0.8789\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.86 - 0s 2us/step - loss: 0.2982 - accuracy: 0.8801\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.88 - 0s 2us/step - loss: 0.2978 - accuracy: 0.8794\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.88 - 0s 2us/step - loss: 0.2975 - accuracy: 0.8796\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.87 - 0s 2us/step - loss: 0.2977 - accuracy: 0.8798\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3102 - accuracy: 0.88 - 0s 2us/step - loss: 0.2976 - accuracy: 0.8797\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.88 - 0s 2us/step - loss: 0.2975 - accuracy: 0.8793\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.87 - 0s 2us/step - loss: 0.2975 - accuracy: 0.8792\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - 0s 2us/step - loss: 0.2975 - accuracy: 0.8792\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.86 - 0s 2us/step - loss: 0.2977 - accuracy: 0.8803\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.86 - 0s 2us/step - loss: 0.2974 - accuracy: 0.8783\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2899 - accuracy: 0.88 - 0s 2us/step - loss: 0.2974 - accuracy: 0.8791\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2775 - accuracy: 0.88 - 0s 2us/step - loss: 0.2976 - accuracy: 0.8798\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2890 - accuracy: 0.87 - 0s 2us/step - loss: 0.2974 - accuracy: 0.8791\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2899 - accuracy: 0.88 - 0s 4us/step - loss: 0.2972 - accuracy: 0.8802\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.87 - 0s 2us/step - loss: 0.2973 - accuracy: 0.8794\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.88 - 0s 2us/step - loss: 0.2972 - accuracy: 0.8797\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.88 - 0s 2us/step - loss: 0.2970 - accuracy: 0.8801\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.87 - 0s 2us/step - loss: 0.2971 - accuracy: 0.8799\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.89 - 0s 2us/step - loss: 0.2969 - accuracy: 0.8807\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.88 - 0s 2us/step - loss: 0.2969 - accuracy: 0.8797\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.87 - 0s 2us/step - loss: 0.2970 - accuracy: 0.8799\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2735 - accuracy: 0.89 - 0s 2us/step - loss: 0.2970 - accuracy: 0.8801\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2754 - accuracy: 0.89 - 0s 2us/step - loss: 0.2968 - accuracy: 0.8801\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.86 - 0s 2us/step - loss: 0.2968 - accuracy: 0.8798\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.88 - 0s 2us/step - loss: 0.2973 - accuracy: 0.8800\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2693 - accuracy: 0.89 - 0s 2us/step - loss: 0.2968 - accuracy: 0.8792\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2754 - accuracy: 0.88 - 0s 2us/step - loss: 0.2968 - accuracy: 0.8800\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3249 - accuracy: 0.86 - 0s 2us/step - loss: 0.2968 - accuracy: 0.8799\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.87 - 0s 2us/step - loss: 0.2968 - accuracy: 0.8796\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.90 - 0s 3us/step - loss: 0.2968 - accuracy: 0.8806\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.88 - 0s 3us/step - loss: 0.2972 - accuracy: 0.8797\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3111 - accuracy: 0.88 - 0s 2us/step - loss: 0.2968 - accuracy: 0.8798\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.89 - 0s 2us/step - loss: 0.2969 - accuracy: 0.8797\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.86 - 0s 3us/step - loss: 0.2965 - accuracy: 0.8806\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3082 - accuracy: 0.88 - 0s 3us/step - loss: 0.2964 - accuracy: 0.8804\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2852 - accuracy: 0.88 - 0s 2us/step - loss: 0.2964 - accuracy: 0.8801\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - 0s 2us/step - loss: 0.2965 - accuracy: 0.8800\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3101 - accuracy: 0.87 - 0s 2us/step - loss: 0.2965 - accuracy: 0.8801\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3097 - accuracy: 0.88 - 0s 2us/step - loss: 0.2966 - accuracy: 0.8802\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2896 - accuracy: 0.88 - 0s 2us/step - loss: 0.2963 - accuracy: 0.8803\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.89 - 0s 2us/step - loss: 0.2963 - accuracy: 0.8798\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.88 - 0s 2us/step - loss: 0.2964 - accuracy: 0.8806\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.88 - 0s 2us/step - loss: 0.2963 - accuracy: 0.8801\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2875 - accuracy: 0.89 - 0s 2us/step - loss: 0.2963 - accuracy: 0.8809\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.87 - 0s 2us/step - loss: 0.2963 - accuracy: 0.8800\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.88 - 0s 2us/step - loss: 0.2963 - accuracy: 0.8807\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.87 - 0s 2us/step - loss: 0.2961 - accuracy: 0.8801\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.88 - 0s 2us/step - loss: 0.2960 - accuracy: 0.8809\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.88 - 0s 2us/step - loss: 0.2960 - accuracy: 0.8808\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.88 - 0s 2us/step - loss: 0.2964 - accuracy: 0.8811\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3075 - accuracy: 0.87 - 0s 2us/step - loss: 0.2962 - accuracy: 0.8793\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.88 - 0s 2us/step - loss: 0.2961 - accuracy: 0.8807\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2654 - accuracy: 0.90 - 0s 2us/step - loss: 0.2960 - accuracy: 0.8803\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.88 - 0s 2us/step - loss: 0.2960 - accuracy: 0.8801\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.86 - 0s 2us/step - loss: 0.2958 - accuracy: 0.8811\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2739 - accuracy: 0.89 - 0s 2us/step - loss: 0.2961 - accuracy: 0.8808\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.87 - 0s 2us/step - loss: 0.2964 - accuracy: 0.8799\n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.88 - 0s 2us/step - loss: 0.2958 - accuracy: 0.8807\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.86 - 0s 2us/step - loss: 0.2958 - accuracy: 0.8803\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.89 - 0s 2us/step - loss: 0.2959 - accuracy: 0.8803\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.88 - 0s 2us/step - loss: 0.2958 - accuracy: 0.8808\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2994 - accuracy: 0.87 - 0s 2us/step - loss: 0.2958 - accuracy: 0.8806\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.87 - 0s 2us/step - loss: 0.2957 - accuracy: 0.8811\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2841 - accuracy: 0.89 - 0s 2us/step - loss: 0.2958 - accuracy: 0.8803\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3041 - accuracy: 0.87 - 0s 2us/step - loss: 0.2957 - accuracy: 0.8794\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2921 - accuracy: 0.87 - 0s 2us/step - loss: 0.2956 - accuracy: 0.8810\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.89 - 0s 2us/step - loss: 0.2957 - accuracy: 0.8811\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.88 - 0s 2us/step - loss: 0.2954 - accuracy: 0.8803\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - 0s 2us/step - loss: 0.2955 - accuracy: 0.8803\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.87 - 0s 2us/step - loss: 0.2955 - accuracy: 0.8801\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.88 - 0s 2us/step - loss: 0.2954 - accuracy: 0.8811\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.89 - 0s 2us/step - loss: 0.2953 - accuracy: 0.8806\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.88 - 0s 2us/step - loss: 0.2955 - accuracy: 0.8807\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.89 - 0s 2us/step - loss: 0.2952 - accuracy: 0.8802\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.87 - 0s 2us/step - loss: 0.2952 - accuracy: 0.8817\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - 0s 2us/step - loss: 0.2953 - accuracy: 0.8817\n",
      "Epoch 78/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.88 - 0s 2us/step - loss: 0.2953 - accuracy: 0.8803\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.87 - 0s 2us/step - loss: 0.2955 - accuracy: 0.8806\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.88 - 0s 2us/step - loss: 0.2953 - accuracy: 0.8801\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3160 - accuracy: 0.88 - 0s 2us/step - loss: 0.2952 - accuracy: 0.8809\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.87 - 0s 2us/step - loss: 0.2951 - accuracy: 0.8803\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.87 - 0s 2us/step - loss: 0.2950 - accuracy: 0.8809\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.88 - 0s 2us/step - loss: 0.2952 - accuracy: 0.8811\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2815 - accuracy: 0.88 - 0s 2us/step - loss: 0.2953 - accuracy: 0.8793\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2862 - accuracy: 0.89 - 0s 2us/step - loss: 0.2951 - accuracy: 0.8813\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.86 - 0s 2us/step - loss: 0.2950 - accuracy: 0.8804\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.87 - 0s 2us/step - loss: 0.2949 - accuracy: 0.8800\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.88 - 0s 2us/step - loss: 0.2951 - accuracy: 0.8802\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.87 - 0s 2us/step - loss: 0.2950 - accuracy: 0.8803\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.87 - 0s 2us/step - loss: 0.2950 - accuracy: 0.8806\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2769 - accuracy: 0.89 - 0s 2us/step - loss: 0.2950 - accuracy: 0.8801\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2782 - accuracy: 0.88 - 0s 2us/step - loss: 0.2949 - accuracy: 0.8807\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2899 - accuracy: 0.87 - 0s 2us/step - loss: 0.2950 - accuracy: 0.8803\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3124 - accuracy: 0.87 - 0s 2us/step - loss: 0.2948 - accuracy: 0.8803\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2629 - accuracy: 0.89 - 0s 2us/step - loss: 0.2947 - accuracy: 0.8806\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.88 - 0s 2us/step - loss: 0.2947 - accuracy: 0.8814\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2935 - accuracy: 0.88 - 0s 2us/step - loss: 0.2947 - accuracy: 0.8811\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.87 - 0s 2us/step - loss: 0.2946 - accuracy: 0.8809\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.3058 - accuracy: 0.87 - 0s 2us/step - loss: 0.2947 - accuracy: 0.8803\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.adam(lr=0.0008)\n",
    "classifier.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "history=classifier.fit(X_train_std, y_train,epochs=100, batch_size=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00b3e5> Q7. Predict the results (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.881\n"
     ]
    }
   ],
   "source": [
    "loss, acc = classifier.evaluate(X_train_std, y_train, verbose=0)\n",
    "print('Train Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(classifier.predict(X_test_std))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since this is a binary classification problem, I am not calculating probabilities of the output, rather using predict directly to identify the most possible class out of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ff31feeb48>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "# plot loss during training\n",
    "\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The above plot shows the Loss reduction graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00b3e5> Q8. Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.849\n"
     ]
    }
   ],
   "source": [
    "loss, acc = classifier.evaluate(X_test_std, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[754  40]\n",
      " [111  95]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       794\n",
      "           1       0.70      0.46      0.56       206\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.79      0.71      0.73      1000\n",
      "weighted avg       0.84      0.85      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr=metrics.classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
